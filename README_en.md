<div align="center">

<img width="1200" height="475" alt="GHBanner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
<h1>Built with AI Studio</h2>
<p>The fastest path from prompt to production with Gemini.</p>
<a href="https://aistudio.google.com/apps">Start building</a>
<h1>Gemini OmniChat</h1>
<p>A high-performance, multi-provider chat interface (Gemini, OpenAI, Ollama) with robust key management.</p>

<p>
  <strong>ğŸ‡ºğŸ‡¸ English</strong> ï½œ <a href="./README.md">ğŸ‡¨ğŸ‡³ ç®€ä½“ä¸­æ–‡</a>
</p>

<!-- Watermark / Disclaimer -->
<br>
<h3 style="color: #cccccc; opacity: 0.5; font-style: italic;">
  âš ï¸ AI Generated Content âš ï¸
</h3>
<p style="color: #999999; font-size: 0.8em; font-style: italic;">
  This entire project â€” including all code, logic, UI design, and this README â€” was generated by Artificial Intelligence.
</p>
<br>

</div>

---

## ğŸš€ Key Features

### Core Connectivity
*   **Multi-Provider Support**: Seamlessly switch between **Google Gemini**, **OpenAI Compatible** endpoints (including local LLMs like vLLM/LM Studio), and **Ollama** (supports Ollama Cloud/Proxy).
*   **High Availability Key Rotation**: Configure multiple API keys with polling strategies to handle rate limits gracefully.
*   **Key Grouping (v1.5)**: Organize API keys into named groups for bulk activation/deactivation and management.

### Advanced AI Capabilities
*   **Thinking Model Support**: Native UI support for Gemini 2.5 "Thinking" models, visualizing `<think>` blocks with collapsible "Thought Process" sections.
*   **Thinking Budget Control**: Adjust the thinking token budget to control reasoning depth.
*   **System Prompts Management**: Create, edit, and toggle multiple system instructions. Includes a full-screen editor.
*   **Context Control**: Configurable history context limits to manage token usage.

### Rich Chat Experience
*   **Markdown & Math**: Full rendering support for Markdown, Code Blocks (with syntax highlighting), and LaTeX math equations.
*   **Message Editing**: Edit user prompts or AI responses to steer the conversation.
*   **Regeneration**: Regenerate responses from any point in the conversation history.
*   **Stats Display**: Real-time display of execution time and token usage (estimated vs exact).

### UI & Customization
*   **Themes**: 10+ themes including VSCode Light/Dark, Twilight, Panda, and localized Kirby mascot adaptation.
*   **Chat History**: Auto-save sessions, export/import as JSON, and auto-summarize titles.
*   **Security Lock**: Optional password or security question protection for privacy.
*   **Script Filters (Middleware)**: Upload JS/TS files to intercept/modify messages (Input/Output) locally in the browser.

## ğŸ›  Getting Started

1.  **Clone:** `git clone https://github.com/HeavenTTT/Gemini-OmniChat-auto.git`
2.  **Install:** `npm install`
3.  **Run:** `npm run dev`
4.  **Open:** [http://localhost:3000](http://localhost:3000)

## ğŸ§© Script Filters (Middleware)

OmniChat allows you to upload custom JavaScript middleware to intercept and modify messages. This is powerful for redacting sensitive data, enforcing formatting, or adding custom logging.

**ğŸ“¥ Download Examples:**
You can download robust, fully commented example scripts (`example_input_filter.js` and `example_output_filter.js`) directly within the app:
1. Go to **Settings** -> **General Settings**.
2. Scroll to **Script Filters (Middleware)**.
3. Click the **Download Example** button.

### Quick Logic Preview

**Input Filter (User -> AI):**
Executes before the message is sent.
```javascript
// Example: Redact sensitive words
const sensitiveWords = ['secret', 'password'];
let modified = input;

sensitiveWords.forEach(word => {
    const regex = new RegExp(word, 'gi');
    modified = modified.replace(regex, '******');
});

return modified;
```

**Output Filter (AI -> User):**
Executes before the response is displayed (works on streams too).
```javascript
// Example: Add a disclaimer
if (!input.includes('AI Generated')) {
    return input + "\n\n> *Processed by local filter*";
}
return input;
```

## ğŸ“¦ Deployment

Optimized for Vercel. Push to GitHub and import to Vercel.

**Note on Ollama:**
This project includes a proxy rewrite in `vercel.json` (`/ollama-proxy`) to help bypass Mixed Content issues when connecting to Ollama instances (e.g. Ollama Cloud) from a secure HTTPS deployment.

---
<div align="center">
  <p style="color: #ccc; font-style: italic; font-size: 0.7rem;">
    * Disclaimer: This project is a demonstration of AI coding capabilities. *
  </p>
</div>

## ğŸ“„ License

MIT License